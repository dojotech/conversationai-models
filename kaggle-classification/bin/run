#!/bin/bash

#
# A script to train the kaggle model remotely using ml-engine.
#
# Setup Steps:
# 1. Install the gcloud SDK
# 2. Authenticate with the GCP project you want to use, `gcloud config set project [my-project]`
# 3. Put the train and test data in Cloud Storage, `gsutil cp [DATA_FILE] gs://[BUCKET_NAME]/`
#

# Edit these!
BUCKET_NAME=kaggle-model-experiments

JOB_NAME=${USER}_kaggle_training
# Note: this must be compatible with cells that have GPUs. us-central1 works.
# See: https://cloud.google.com/ml-engine/docs/using-gpus
REGION=us-central1

DATE=`date '+%Y%m%d_%H%M%S'`
OUTPUT_PATH=gs://${BUCKET_NAME}/models/${USER}/${DATE}
HPARAM_CONFIG=hparam_config.yaml

echo "Writing to $OUTPUT_PATH"

# Remote
gcloud ml-engine jobs submit training ${JOB_NAME}_${DATE} \
    --job-dir ${OUTPUT_PATH} \
    --runtime-version 1.4 \
    --config ${HPARAM_CONFIG} \
    --module-name trainer.model \
    --package-path trainer/ \
    --region $REGION \
    --verbosity debug \
    -- \
    --train_data gs://${BUCKET_NAME}/train.csv \
    --y_class toxic \
    --train_steps 5000 \
    --saved_model_dir gs://${BUCKET_NAME}/saved_graph/${USER}/${DATE} \
    --model cnn


echo "You can view the tensorboard for this job with the command:"
echo ""
echo -e "\t tensorboard --logdir=${OUTPUT_PATH}"
echo ""
echo "And on your browser navigate to:"
echo ""
echo -e "\t http://localhost:6006/#scalars"
echo ""
echo "This will populate after a model checkpoint is saved."
echo ""
